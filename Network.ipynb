{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491746af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918987b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logger = logging.getLogger()\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "settings = dict()\n",
    "store = dict()\n",
    "\n",
    "settings = {\n",
    "    \"data_root\": \"handwriting_cvl_data/words/\",\n",
    "    \"manual_seed\": 42,\n",
    "    \"nc\": 1,\n",
    "    \"nz\": 100,\n",
    "    \"ngf\": 64,\n",
    "    \"ndf\": 64,\n",
    "    \"num_workers\": 32,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 5,\n",
    "    \"lr\": 0.0002,\n",
    "    \"beta1\": 0.5,\n",
    "    \"image_size\": (64, 64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba33049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithClasses(ImageFolder):\n",
    "    def __getitem__(self, idx):\n",
    "        item = super().__getitem__(idx)\n",
    "        paths = self.imgs[idx][0].split(\"/\")\n",
    "        filename = paths[len(paths) - 1].split(\".\")[0]\n",
    "        writer_id, page_num, line_num, word_num, word = filename.split(\"-\", 4)\n",
    "        return (item + (word, writer_id,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(initial=False):\n",
    "    if initial:\n",
    "        root_logger.setLevel(logging.INFO)\n",
    "        root_logger.addHandler(logging.FileHandler(\"Network.log\", \"w\", \"utf-8\"))\n",
    "\n",
    "    if \"manual_seed\" in settings:\n",
    "        manual_seed = settings[\"manual_seed\"]\n",
    "        random.seed(manual_seed)\n",
    "        torch.manual_seed(manual_seed)\n",
    "        print(f\"[setup] Set manual seed to: {manual_seed}\")\n",
    "\n",
    "setup(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eac5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data_root = settings[\"data_root\"]\n",
    "    batch_size = settings[\"batch_size\"]\n",
    "    image_size = settings[\"image_size\"]\n",
    "    num_workers = settings[\"num_workers\"]\n",
    "\n",
    "    dataset = ImageFolderWithClasses(root=data_root, transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ]))\n",
    "\n",
    "    words = set()\n",
    "    writers = set()\n",
    "    for i in range(len(dataset)):\n",
    "        words.add(dataset[i][2])\n",
    "        writers.add(dataset[i][3])\n",
    "\n",
    "    words = sorted(list(words))\n",
    "    word_to_idx = { word: i for i, word in enumerate(words) }\n",
    "\n",
    "    writers = sorted(list(writers))\n",
    "    writer_to_idx = { writer: i for i, writer in enumerate(writers) }\n",
    "\n",
    "    store[\"dataloader\"] = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    store[\"dataset\"] = dataset\n",
    "\n",
    "    store[\"nwords\"] = len(words)\n",
    "    store[\"nwriters\"] = len(writers)\n",
    "\n",
    "    store[\"word_to_idx\"] = word_to_idx\n",
    "    store[\"writer_to_idx\"] = writer_to_idx\n",
    "    store[\"idx_to_word\"] = { val: key for key, val in store[\"word_to_idx\"].items() }\n",
    "    store[\"idx_to_class\"] = { val: key for key, val in store[\"writer_to_idx\"].items() }\n",
    "    store[\"device\"] = torch.device(\"cpu\")\n",
    "\n",
    "setup()\n",
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ee7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    m_type = type(m)\n",
    "    if m_type in [nn.ConvTranspose2d, nn.Conv2d]:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif m_type in [nn.BatchNorm2d]:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc8070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = settings[\"nc\"]\n",
    "nz = settings[\"nz\"]\n",
    "ngf = settings[\"ngf\"]\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, image_input):\n",
    "        return self.main(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_generator():\n",
    "    store[\"netG\"] = Generator().to(store[\"device\"])\n",
    "    store[\"netG\"].apply(init_weights)\n",
    "    print(store[\"netG\"])\n",
    "\n",
    "setup()\n",
    "construct_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9849bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = settings[\"nc\"]\n",
    "nz = settings[\"nz\"]\n",
    "ndf = settings[\"ndf\"]\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image_input):\n",
    "        return self.main(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_discriminator():\n",
    "    store[\"netD\"] = Discriminator().to(store[\"device\"])\n",
    "    store[\"netD\"].apply(init_weights)\n",
    "    print(store[\"netD\"])\n",
    "\n",
    "setup()\n",
    "construct_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    dataloader = store[\"dataloader\"]\n",
    "    device = store[\"device\"]\n",
    "    netD = store[\"netD\"]\n",
    "    netG = store[\"netG\"]\n",
    "\n",
    "    num_epochs = settings[\"num_epochs\"]\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=settings[\"lr\"], betas=(settings[\"beta1\"], 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=settings[\"lr\"], betas=(settings[\"beta1\"], 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    real_label = 1.0\n",
    "    fake_label = 0.0\n",
    "\n",
    "    def train_discriminator(data):\n",
    "        netD.zero_grad()\n",
    "        real_data = data[0].to(device)\n",
    "        b_size = real_data.size(0)\n",
    "\n",
    "        # discriminate real image data\n",
    "        real_output = netD(real_data)\n",
    "        real_output = real_output.view(-1)\n",
    "\n",
    "        # calculate error using tensor of real_labels\n",
    "        # the goal is to get the discriminator to detect real instances\n",
    "        real_labels = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        errD_real = criterion(real_output, real_labels)\n",
    "\n",
    "        # calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "\n",
    "        # generate fake data\n",
    "        # and detach gradients from the output because we're training the discriminator\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        generated_data = netG(noise).detach()\n",
    "\n",
    "        # discriminate fake image data\n",
    "        fake_output = netD(generated_data).view(-1)\n",
    "\n",
    "        # calculate error using tensor of fake_labels\n",
    "        # the goal is to get discriminator to detect fake instances\n",
    "        fake_labels = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
    "        errD_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "\n",
    "        # return loss and discriminator mean \n",
    "        optimizerD.step()\n",
    "        return errD_real + errD_fake\n",
    "\n",
    "    def train_generator(data):\n",
    "        netG.zero_grad()\n",
    "        real_data = data[0].to(device)\n",
    "        b_size = real_data.size(0)\n",
    "\n",
    "        # generate fake data\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        generated = netG(noise)\n",
    "\n",
    "        # discriminate fake image data\n",
    "        fake_output = netD(generated).view(-1)\n",
    "\n",
    "        # calculate error using tensor of real_labels\n",
    "        # the goal is to get the generator to generate \"real\" instances\n",
    "        real_labels = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        errG = criterion(fake_output, real_labels)\n",
    "\n",
    "        # calculate gradients for G\n",
    "        errG.backward()\n",
    "\n",
    "        # return loss and discriminator mean \n",
    "        optimizerG.step()\n",
    "        return errG\n",
    "\n",
    "    root_logger.info(\"Starting training loop...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            errD = train_discriminator(data)\n",
    "            errG = train_generator(data)\n",
    "\n",
    "            D_losses.append(errD.item())\n",
    "            G_losses.append(errG.item())\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                epoch_progress = f\"{epoch}/{num_epochs} epochs\"\n",
    "                iteration_progress = f\"{i}/{len(dataloader)} iterations\"\n",
    "                root_logger.info(f\"{epoch_progress}, {iteration_progress}, Loss_D: {errD.item()}, Loss_G: {errG.item()}\")\n",
    "\n",
    "    torch.save(netG.state_dict(), \"models/Network.G.pth\")\n",
    "    torch.save(netD.state_dict(), \"models/Network.D.pth\")\n",
    "\n",
    "    root_logger.info(\"training complete\")\n",
    "    root_logger.info(\"models saved\")\n",
    "\n",
    "setup()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41add66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    dataloader = store[\"dataloader\"]\n",
    "    device = store[\"device\"]\n",
    "    netG = store[\"netG\"]\n",
    "    nz = settings[\"nz\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Iterations vs. Loss\")\n",
    "    plt.plot(G_losses, label=\"G\")\n",
    "    plt.plot(D_losses, label=\"D\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    real_images = next(iter(dataloader))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.transpose(vutils.make_grid(real_images[0].to(device)[:64], padding=5, normalize=True).cpu(), (1, 2, 0)))\n",
    "\n",
    "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "    fake_images = netG(fixed_noise).detach().cpu()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.transpose(vutils.make_grid(fake_images, padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
